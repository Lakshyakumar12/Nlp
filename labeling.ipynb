{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "   print(\"gpu\")\n",
    "else: \n",
    "    torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Python310\\lib\\site-packages\\accelerate\\accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a4dc9eb32245b3a00d6be4cb39d690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/939 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7137, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.03}\n",
      "{'loss': 0.6671, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.06}\n",
      "{'loss': 0.6619, 'learning_rate': 3e-06, 'epoch': 0.1}\n",
      "{'loss': 0.6665, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.13}\n",
      "{'loss': 0.6457, 'learning_rate': 5e-06, 'epoch': 0.16}\n",
      "{'loss': 0.6176, 'learning_rate': 6e-06, 'epoch': 0.19}\n",
      "{'loss': 0.6069, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.22}\n",
      "{'loss': 0.5384, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.26}\n",
      "{'loss': 0.4721, 'learning_rate': 9e-06, 'epoch': 0.29}\n",
      "{'loss': 0.5301, 'learning_rate': 1e-05, 'epoch': 0.32}\n",
      "{'loss': 0.4774, 'learning_rate': 1.1000000000000001e-05, 'epoch': 0.35}\n",
      "{'loss': 0.4778, 'learning_rate': 1.2e-05, 'epoch': 0.38}\n",
      "{'loss': 0.46, 'learning_rate': 1.3000000000000001e-05, 'epoch': 0.42}\n",
      "{'loss': 0.424, 'learning_rate': 1.4000000000000001e-05, 'epoch': 0.45}\n",
      "{'loss': 0.3889, 'learning_rate': 1.5e-05, 'epoch': 0.48}\n",
      "{'loss': 0.4312, 'learning_rate': 1.6000000000000003e-05, 'epoch': 0.51}\n",
      "{'loss': 0.3931, 'learning_rate': 1.7000000000000003e-05, 'epoch': 0.54}\n",
      "{'loss': 0.4215, 'learning_rate': 1.8e-05, 'epoch': 0.58}\n",
      "{'loss': 0.3817, 'learning_rate': 1.9e-05, 'epoch': 0.61}\n",
      "{'loss': 0.2926, 'learning_rate': 2e-05, 'epoch': 0.64}\n",
      "{'loss': 0.3363, 'learning_rate': 2.1e-05, 'epoch': 0.67}\n",
      "{'loss': 0.3705, 'learning_rate': 2.2000000000000003e-05, 'epoch': 0.7}\n",
      "{'loss': 0.3292, 'learning_rate': 2.3000000000000003e-05, 'epoch': 0.73}\n",
      "{'loss': 0.368, 'learning_rate': 2.4e-05, 'epoch': 0.77}\n",
      "{'loss': 0.2338, 'learning_rate': 2.5e-05, 'epoch': 0.8}\n",
      "{'loss': 0.3425, 'learning_rate': 2.6000000000000002e-05, 'epoch': 0.83}\n",
      "{'loss': 0.3247, 'learning_rate': 2.7000000000000002e-05, 'epoch': 0.86}\n",
      "{'loss': 0.3395, 'learning_rate': 2.8000000000000003e-05, 'epoch': 0.89}\n",
      "{'loss': 0.3958, 'learning_rate': 2.9e-05, 'epoch': 0.93}\n",
      "{'loss': 0.3629, 'learning_rate': 3e-05, 'epoch': 0.96}\n",
      "{'loss': 0.3345, 'learning_rate': 3.1e-05, 'epoch': 0.99}\n",
      "{'loss': 0.341, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.02}\n",
      "{'loss': 0.264, 'learning_rate': 3.3e-05, 'epoch': 1.05}\n",
      "{'loss': 0.268, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.09}\n",
      "{'loss': 0.3058, 'learning_rate': 3.5e-05, 'epoch': 1.12}\n",
      "{'loss': 0.2574, 'learning_rate': 3.6e-05, 'epoch': 1.15}\n",
      "{'loss': 0.2462, 'learning_rate': 3.7e-05, 'epoch': 1.18}\n",
      "{'loss': 0.1658, 'learning_rate': 3.8e-05, 'epoch': 1.21}\n",
      "{'loss': 0.2702, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.25}\n",
      "{'loss': 0.389, 'learning_rate': 4e-05, 'epoch': 1.28}\n",
      "{'loss': 0.2013, 'learning_rate': 4.1e-05, 'epoch': 1.31}\n",
      "{'loss': 0.3261, 'learning_rate': 4.2e-05, 'epoch': 1.34}\n",
      "{'loss': 0.2953, 'learning_rate': 4.3e-05, 'epoch': 1.37}\n",
      "{'loss': 0.2022, 'learning_rate': 4.4000000000000006e-05, 'epoch': 1.41}\n",
      "{'loss': 0.2838, 'learning_rate': 4.5e-05, 'epoch': 1.44}\n",
      "{'loss': 0.3153, 'learning_rate': 4.600000000000001e-05, 'epoch': 1.47}\n",
      "{'loss': 0.3409, 'learning_rate': 4.7e-05, 'epoch': 1.5}\n",
      "{'loss': 0.2678, 'learning_rate': 4.8e-05, 'epoch': 1.53}\n",
      "{'loss': 0.2832, 'learning_rate': 4.9e-05, 'epoch': 1.57}\n",
      "{'loss': 0.2518, 'learning_rate': 5e-05, 'epoch': 1.6}\n",
      "{'loss': 0.4079, 'learning_rate': 4.886104783599089e-05, 'epoch': 1.63}\n",
      "{'loss': 0.2467, 'learning_rate': 4.772209567198178e-05, 'epoch': 1.66}\n",
      "{'loss': 0.3012, 'learning_rate': 4.658314350797267e-05, 'epoch': 1.69}\n",
      "{'loss': 0.2314, 'learning_rate': 4.5444191343963556e-05, 'epoch': 1.73}\n",
      "{'loss': 0.2724, 'learning_rate': 4.4305239179954444e-05, 'epoch': 1.76}\n",
      "{'loss': 0.3575, 'learning_rate': 4.316628701594533e-05, 'epoch': 1.79}\n",
      "{'loss': 0.2445, 'learning_rate': 4.202733485193622e-05, 'epoch': 1.82}\n",
      "{'loss': 0.2837, 'learning_rate': 4.088838268792711e-05, 'epoch': 1.85}\n",
      "{'loss': 0.2466, 'learning_rate': 3.9749430523918e-05, 'epoch': 1.88}\n",
      "{'loss': 0.2039, 'learning_rate': 3.8610478359908886e-05, 'epoch': 1.92}\n",
      "{'loss': 0.2027, 'learning_rate': 3.7471526195899774e-05, 'epoch': 1.95}\n",
      "{'loss': 0.3475, 'learning_rate': 3.633257403189066e-05, 'epoch': 1.98}\n",
      "{'loss': 0.2415, 'learning_rate': 3.519362186788155e-05, 'epoch': 2.01}\n",
      "{'loss': 0.0936, 'learning_rate': 3.405466970387244e-05, 'epoch': 2.04}\n",
      "{'loss': 0.0508, 'learning_rate': 3.291571753986333e-05, 'epoch': 2.08}\n",
      "{'loss': 0.1224, 'learning_rate': 3.1776765375854216e-05, 'epoch': 2.11}\n",
      "{'loss': 0.3318, 'learning_rate': 3.0637813211845104e-05, 'epoch': 2.14}\n",
      "{'loss': 0.1971, 'learning_rate': 2.949886104783599e-05, 'epoch': 2.17}\n",
      "{'loss': 0.1799, 'learning_rate': 2.835990888382688e-05, 'epoch': 2.2}\n",
      "{'loss': 0.1825, 'learning_rate': 2.722095671981777e-05, 'epoch': 2.24}\n",
      "{'loss': 0.2012, 'learning_rate': 2.608200455580866e-05, 'epoch': 2.27}\n",
      "{'loss': 0.2115, 'learning_rate': 2.4943052391799546e-05, 'epoch': 2.3}\n",
      "{'loss': 0.0881, 'learning_rate': 2.3804100227790434e-05, 'epoch': 2.33}\n",
      "{'loss': 0.1001, 'learning_rate': 2.2665148063781322e-05, 'epoch': 2.36}\n",
      "{'loss': 0.1178, 'learning_rate': 2.152619589977221e-05, 'epoch': 2.4}\n",
      "{'loss': 0.0658, 'learning_rate': 2.03872437357631e-05, 'epoch': 2.43}\n",
      "{'loss': 0.1924, 'learning_rate': 1.9248291571753987e-05, 'epoch': 2.46}\n",
      "{'loss': 0.1419, 'learning_rate': 1.8109339407744876e-05, 'epoch': 2.49}\n",
      "{'loss': 0.1299, 'learning_rate': 1.6970387243735764e-05, 'epoch': 2.52}\n",
      "{'loss': 0.1181, 'learning_rate': 1.5831435079726652e-05, 'epoch': 2.56}\n",
      "{'loss': 0.1741, 'learning_rate': 1.469248291571754e-05, 'epoch': 2.59}\n",
      "{'loss': 0.0995, 'learning_rate': 1.3553530751708429e-05, 'epoch': 2.62}\n",
      "{'loss': 0.1897, 'learning_rate': 1.2414578587699317e-05, 'epoch': 2.65}\n",
      "{'loss': 0.1271, 'learning_rate': 1.1275626423690206e-05, 'epoch': 2.68}\n",
      "{'loss': 0.1012, 'learning_rate': 1.0136674259681094e-05, 'epoch': 2.72}\n",
      "{'loss': 0.1493, 'learning_rate': 8.997722095671982e-06, 'epoch': 2.75}\n",
      "{'loss': 0.1834, 'learning_rate': 7.85876993166287e-06, 'epoch': 2.78}\n",
      "{'loss': 0.1084, 'learning_rate': 6.719817767653759e-06, 'epoch': 2.81}\n",
      "{'loss': 0.1221, 'learning_rate': 5.580865603644647e-06, 'epoch': 2.84}\n",
      "{'loss': 0.0506, 'learning_rate': 4.4419134396355355e-06, 'epoch': 2.88}\n",
      "{'loss': 0.1338, 'learning_rate': 3.302961275626424e-06, 'epoch': 2.91}\n",
      "{'loss': 0.0752, 'learning_rate': 2.164009111617312e-06, 'epoch': 2.94}\n",
      "{'loss': 0.0941, 'learning_rate': 1.0250569476082005e-06, 'epoch': 2.97}\n",
      "{'train_runtime': 23591.799, 'train_samples_per_second': 0.636, 'train_steps_per_second': 0.04, 'train_loss': 0.2892609660744794, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5eab0be7f4940e1bd28f28f7d205745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.65683913230896, 'eval_accuracy': 0.6533066132264529, 'eval_spearman_correlation': 0.36353853629277566, 'eval_runtime': 55.8508, 'eval_samples_per_second': 8.935, 'eval_steps_per_second': 0.143, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import numpy as np\n",
    "import json\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=2)\n",
    "\n",
    "# Determine the computing device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Function to encode the data\n",
    "def encode_data(data):\n",
    "    texts = [f\"[HYP] {item['hyp']} [TGT] {item['tgt']} [SRC] {item['src']} [REF] {item['ref']} [TASK] {item['task']}\" for item in data]\n",
    "    labels = [1 if item['label'] == 'Hallucination' else 0 for item in data]\n",
    "    prop_hallucination = [float(item.get('p(Hallucination)', 0)) for item in data]\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=512)\n",
    "    return encodings, labels, prop_hallucination\n",
    "\n",
    "# Load and encode the data\n",
    "with open('newtrain_data.json', 'r', encoding='utf-8') as f:\n",
    "    train_data = json.load(f)\n",
    "train_encodings, train_labels, _ = encode_data(train_data)\n",
    "\n",
    "with open('val.model-agnostic.json', 'r', encoding='utf-8') as f:\n",
    "    val_data = json.load(f)\n",
    "val_encodings, val_labels, val_prop_hallucination = encode_data(val_data)\n",
    "\n",
    "# Define the dataset class\n",
    "class HallucinationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = {key: torch.tensor(val) for key, val in encodings.items()}\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: self.encodings[key][idx] for key in self.encodings}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = HallucinationDataset(train_encodings, train_labels)\n",
    "val_dataset = HallucinationDataset(val_encodings, val_labels)\n",
    "\n",
    "# DataLoader setup\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, pin_memory=True)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "# Define compute_metrics function for accuracy and Spearman correlation\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = np.argmax(pred.predictions, axis=-1)\n",
    "    pred_probs = pred.predictions[:, 1]  # probabilities for the positive class\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    spearman_corr = spearmanr(val_prop_hallucination, pred_probs).correlation\n",
    "    return {'accuracy': acc, 'spearman_correlation': spearman_corr}\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Train and evaluate\n",
    "trainer.train()\n",
    "results = trainer.evaluate()\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./saved_tokenizer\\\\tokenizer_config.json',\n",
       " './saved_tokenizer\\\\special_tokens_map.json',\n",
       " './saved_tokenizer\\\\vocab.txt',\n",
       " './saved_tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path = './saved_model'\n",
    "tokenizer_save_path = './saved_tokenizer'\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(tokenizer_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accuracy, predictions,f1\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Call the evaluation function\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m accuracy, predictions,f1 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28mprint\u001b[39m(f1)\n",
      "Cell \u001b[1;32mIn[1], line 60\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, loader)\u001b[0m\n\u001b[0;32m     58\u001b[0m         preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(outputs\u001b[38;5;241m.\u001b[39mlogits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     59\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m---> 60\u001b[0m         actual_labels\u001b[38;5;241m.\u001b[39mextend(\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabels\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# Calculate accuracy and other metrics if needed\u001b[39;00m\n\u001b[0;32m     63\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(actual_labels, predictions)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'labels'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "# Load the trained model and tokenizer\n",
    "model_path = './saved_model'\n",
    "tokenizer_path = './saved_tokenizer'\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path, num_labels=2)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Function to encode the data\n",
    "def encode_data(data, tokenizer):\n",
    "    # Provide default values if keys are missing\n",
    "    texts = [\n",
    "        f\"[HYP] {item.get('hyp', 'Missing HYP')} \"\n",
    "        f\"[TGT] {item.get('tgt', 'Missing TGT')} \"\n",
    "        f\"[SRC] {item.get('src', 'Missing SRC')} \"\n",
    "        f\"[REF] {item.get('ref', 'Missing REF')} \"\n",
    "        f\"[TASK] {item.get('task', 'Missing TASK')}\"\n",
    "        for item in data\n",
    "    ]\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "    return encodings['input_ids'], encodings['attention_mask']\n",
    "\n",
    "# Load and encode test data\n",
    "with open('val.model-agnostic.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "test_input_ids, test_attention_masks = encode_data(test_data, tokenizer)\n",
    "\n",
    "# DataLoader setup\n",
    "class TestDataLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, attention_masks):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {'input_ids': self.input_ids[idx], 'attention_mask': self.attention_masks[idx]}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "test_dataset = TestDataLoader(test_input_ids, test_attention_masks)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Prediction\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actual_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy and other metrics if needed\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    f1 = f1_score(actual_labels, preds)\n",
    "    return accuracy, predictions\n",
    "\n",
    "# Call the evaluation function\n",
    "accuracy, predictions = evaluate_model(model, test_loader)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Optionally, save predictions to CSV\n",
    "prediction_data = pd.DataFrame({'Predictions': predictions})\n",
    "prediction_data.to_csv('predictions.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5906666666666667\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "# Assuming tokenizer and model are loaded and the model is placed on the correct device\n",
    "\n",
    "# Function to encode the data and handle the label array\n",
    "def encode_data_with_labels(data, tokenizer):\n",
    "    texts = []\n",
    "    binary_labels = []  # 0 for \"Not Hallucination\", 1 for \"Hallucination\"\n",
    "\n",
    "    for item in data:\n",
    "        hyp = item.get('hyp', 'Missing HYP')\n",
    "        tgt = item.get('tgt', 'Missing TGT')\n",
    "        src = item.get('src', 'Missing SRC')\n",
    "        ref = item.get('ref', 'Missing REF') if 'ref' in item else 'No REF'\n",
    "        task = item.get('task', 'Missing TASK')\n",
    "        # Interpret the label list: 0 if all entries are \"Not Hallucination\", 1 otherwise\n",
    "        label = 1 if any(label == \"Hallucination\" for label in item.get('labels', [])) else 0\n",
    "        texts.append(f\"[HYP] {hyp} [TGT] {tgt} [SRC] {src} [REF] {ref} [TASK] {task}\")\n",
    "        binary_labels.append(label)\n",
    "\n",
    "    encodings = tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "    return encodings['input_ids'], encodings['attention_mask'], torch.tensor(binary_labels)\n",
    "\n",
    "# Load test data and encode it\n",
    "with open('test.model-agnostic.json', 'r', encoding='utf-8') as f:\n",
    "    test_data = json.load(f)\n",
    "test_input_ids, test_attention_masks, test_labels = encode_data_with_labels(test_data, tokenizer)\n",
    "\n",
    "# DataLoader for the test data\n",
    "class TestDataLoader(torch.utils.data.Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],\n",
    "            'attention_mask': self.attention_masks[idx],\n",
    "            'labels': self.labels[idx]\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_ids)\n",
    "\n",
    "test_dataset = TestDataLoader(test_input_ids, test_attention_masks, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Model evaluation function assuming it returns predictions\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            outputs = model(batch['input_ids'].to(device), attention_mask=batch['attention_mask'].to(device))\n",
    "            preds = torch.argmax(outputs.logits, dim=1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            actual_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "    # Calculate accuracy and other metrics if needed\n",
    "    accuracy = accuracy_score(actual_labels, predictions)\n",
    "    f1 = f1_score(actual_labels, preds)\n",
    "    return accuracy, predictions\n",
    "\n",
    "# Call the evaluation function\n",
    "accuracy, predictions = evaluate_model(model, test_loader)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Optionally, save predictions to CSV\n",
    "prediction_data = pd.DataFrame({'Predictions': predictions})\n",
    "prediction_data.to_csv('predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
